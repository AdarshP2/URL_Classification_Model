{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74bf78f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
    "model.save_pretrained('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5e0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.netflix.com/browse\n",
      "Predicted Category: Travel\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Configure Selenium webdriver (replace with appropriate webdriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "url =  'https://www.netflix.com/browse'  # Replace with the URL you want to classify\n",
    "driver.get(url)\n",
    "\n",
    "# Retrieve the HTML content\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Close the Selenium webdriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract relevant information from the parsed HTML\n",
    "description = soup.find('meta', {'name': 'description'})['content']\n",
    "\n",
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Preprocess the description\n",
    "preprocessed_description = tokenizer.encode_plus(description, add_special_tokens=True, truncation=True,\n",
    "                                                 max_length=512, padding='max_length', return_tensors='pt')\n",
    "\n",
    "# Obtain the input tensors\n",
    "input_ids = preprocessed_description['input_ids']\n",
    "attention_mask = preprocessed_description['attention_mask']\n",
    "\n",
    "# Load the pre-trained DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
    "#model.load_state_dict(torch.load(r'C:\\Users\\KIIT\\Desktop\\QuinnoxProject\\model.pth'))  # Load your trained model\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform inference on the input tensors\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Get the predicted category\n",
    "predicted_category = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Define the category mapping\n",
    "category_mapping = {\n",
    "    0: 'Sports',\n",
    "    1: 'Travel',\n",
    "    2: 'Adult',\n",
    "    3: 'Entertainment'\n",
    "}\n",
    "\n",
    "# Get the predicted category label\n",
    "predicted_category_label = category_mapping[predicted_category]\n",
    "\n",
    "# Print the predicted category label\n",
    "print(f\"URL: {url}\")\n",
    "print(f\"Predicted Category: {predicted_category_label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f5713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f97424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d17cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0445fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410567e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefad71f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
